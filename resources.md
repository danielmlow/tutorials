
# Python
- Next-generation Python notebooks: https://marimo.io/

# Speech as a tool in clinical trials
- Screening tool: https://www.sciencedirect.com/science/article/abs/pii/S0165178124003901

# Design
- Figma: modular, save section in one page and it populates everywhere. Prototype function for a demo since all pages are linked. 

# Reducing stigma
- World Health Organization. (2024). Mosaic toolkit to end stigma and discrimination in mental health. In Mosaic toolkit to end stigma and discrimination in mental health. https://www.who.int/europe/publications/i/item/9789289061384



# AI Code Assistants
- https://www.builder.io/blog/cursor-vs-windsurf-vs-github-copilot

# AI Agents
- course: https://llmagents-learning.org/sp25 
- https://generalagents.com/ace/

# RAG
- https://microsoft.github.io/graphrag/ 

# AI for Scientific discovery
- https://www.futurehouse.org/research-announcements/launching-futurehouse-platform-ai-agents

# Speech to text / automated speech recognition
- fast and open source: https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2 

# Get Data
- Open-source: Crawl website with LLM: https://github.com/unclecode/crawl4ai  

# Psychedelic counselor
- https://chatgpt.com/g/g-680126b5bc288191a17c8b01d4cc4773-psychedelic-hotline?mc_cid=f4f0eb10e7&mc_eid=bf933975ba 

# AI and values
- https://www.nejm.org/doi/abs/10.1056/NEJMra2214183

# AI privacy 
- Nasr et al (2023). Scalable Extraction of Training Data from (Production) Language Models. https://arxiv.org/abs/2201.10351
- Vamosi, S., Platzer, M., & Reutterer, T. (2022). AI-based re-identification of behavioral clickstream data. arXiv preprint arXiv:2201.10351.

# Designing
- Canva: for nondesigners
- Figma: for designers




# LLMs

## Introduction to LLMs:
- Brief: https://www.youtube.com/watch?v=LPZh9BOjkQs
- More in depth: https://www.youtube.com/watch?v=KJtZARuO3JY
- Advanced: https://www.youtube.com/watch?v=9-Jl0dxWQs8&vl=en 

# LLM API
- openrouter: access all models using the same code

## LLMs and psychotherapy and mental health
- Google: Lawrence HR, Schneider RA, Rubin SB, Mataric ́ MJ, McDuff DJ, Jones Bell M. The Opportunities and Risks of Large Language Models in Mental Health JMIR Ment Health 2024;11:e59479 doi: 10.2196/59479
- First RCT for psychotherapy: Heinz, M. V., Mackin, D. M., Trudeau, B. M., Bhattacharya, S., Wang, Y., Banta, H. A., ... & Jacobson, N. C. (2025). Randomized trial of a generative ai chatbot for mental health treatment. NEJM AI, 2(4), AIoa2400802.
- Stade, E. C., Toward Responsible Development and Evaluation of LLMs in Psychotherapy
- Several LLMs have been shown to provide responses to clinical questions that are empathetic, accurate, and high quality:
  - Ayers JW, Poliak A, Dredze M, Leas EC, Zhu Z, Kelley JB, et al. Comparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum. JAMA Intern Med. 2023;183: 589–596.
  - Giorgi S, Isman K, Liu T, Fried Z, Sedoc J, Curtis B. Evaluating generative AI responses to real-world drug-related questions. Psychiatry Res. 2024;339: 116058.
- when you control for who the person thinks is answering (AI vs human response), people prefer responses from human even if an AI model authored it (and they think it was a human): Rubin, M., Li, J. Z., Zimmerman, F., Ong, D. C., Goldenberg, A., & Perry, A. (2025). Comparing the value of perceived human versus AI-generated empathy. Nature Human Behaviour, 1-15.

### Sychophancy
The problem of sychophancy (over-agreeing and not challenging enough): 
- Sharma, M., Tong, M., Korbak, T., Duvenaud, D., Askell, A., Bowman, S. R., ... & Perez, E. (2023). Towards understanding sycophancy in language models. arXiv preprint arXiv:2310.13548.
- Malmqvist, L. (2025, June). Sycophancy in large language models: Causes and mitigations. In Intelligent Computing-Proceedings of the Computing Conference (pp. 61-74). Cham: Springer Nature Switzerland.

## LLMs and Psychology
- Mihalcea, R., Biester, L., Boyd, R. L., Jin, Z., Perez-Rosas, V., Wilson, S., & Pennebaker, J. W. (2024). How developments in natural language processing help us in understanding human behaviour. Nature Human Behaviour, 8(10), 1877-1889.
- Stade, E. C., Stirman, S. W., Ungar, L. H., Boland, C. L., Schwartz, H. A., Yaden, D. B., ... & Eichstaedt, J. C. (2024). Large language models could change the future of behavioral healthcare: a proposal for responsible development and evaluation. NPJ Mental Health Research, 3(1), 12.

## Suicide risk assessment
- Donnelly (2025). Exploring the Potential of Large Language Models for Automated Safety Plan Scoring in Outpatient Mental Health Settings. 


## Formatting outputs
- Grammar: https://github.com/ggml-org/llama.cpp/blob/master/grammars/README.md
  - only works with open source llama cpp (platform, not model) models
  - restricts tokens before they are generated instead of post-processing.


  
 

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielmlow/tutorials/blob/main/text/reddit_download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDM-BZ0KVB-c",
        "outputId": "a0ad91b8-4143-463d-b90a-ea41e2d5b5e3"
      },
      "outputs": [],
      "source": [
        "!pip install praw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_74cQVCtVB-c"
      },
      "source": [
        "Search for similar reddits here:\n",
        "https://anvaka.github.io/sayit/?query=GriefSupport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbNFuY_8VB-d"
      },
      "outputs": [],
      "source": [
        "sample_size = 100\n",
        "\n",
        "subreddits = ['bullying',\n",
        " 'abusesurvivors',\n",
        " 'sexualassault',\n",
        " 'relationship_advice',\n",
        " 'GriefSupport',\n",
        " 'lonely',\n",
        " 'Anxiety',\n",
        " 'depression',\n",
        " 'asktransgender',\n",
        " 'EatingDisorders',\n",
        " 'addiction']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0Mz0BapVB-d"
      },
      "outputs": [],
      "source": [
        "class RedditSampler:\n",
        "    def __init__(self, client_id: str, client_secret: str, user_agent: str):\n",
        "        self.reddit = praw.Reddit(\n",
        "            client_id=client_id,\n",
        "            client_secret=client_secret,\n",
        "            user_agent=user_agent\n",
        "        )\n",
        "\n",
        "    def get_samples(\n",
        "        self,\n",
        "        subreddits: List[str],\n",
        "        sample_size: int = 6000,\n",
        "        sleep_amount: float = 0.1,\n",
        "        submission_type: str = \"all\"\n",
        "    ) -> pd.DataFrame:\n",
        "        all_submissions = []\n",
        "        sorts = ['new', 'top', 'controversial', 'hot']\n",
        "        time_filters = ['all', 'year', 'month', 'week']\n",
        "\n",
        "        for subreddit_name in subreddits:\n",
        "            try:\n",
        "                subreddit = self.reddit.subreddit(subreddit_name)\n",
        "                sub_samples = set()  # Using set to avoid duplicates\n",
        "\n",
        "                for sort in sorts:\n",
        "                    if len(sub_samples) >= sample_size:\n",
        "                        break\n",
        "\n",
        "                    for time_filter in time_filters:\n",
        "                        if len(sub_samples) >= sample_size:\n",
        "                            break\n",
        "\n",
        "                        try:\n",
        "                            if sort == 'new':\n",
        "                                submissions = subreddit.new(limit=1000)\n",
        "                            elif sort == 'hot':\n",
        "                                submissions = subreddit.hot(limit=1000)\n",
        "                            else:\n",
        "                                submissions = getattr(subreddit, sort)(time_filter=time_filter, limit=1000)\n",
        "\n",
        "                            for submission in submissions:\n",
        "                                if len(sub_samples) >= sample_size:\n",
        "                                    break\n",
        "\n",
        "                                if submission_type != \"all\":\n",
        "                                    if submission_type == \"self\" and not submission.is_self:\n",
        "                                        continue\n",
        "                                    if submission_type == \"link\" and submission.is_self:\n",
        "                                        continue\n",
        "\n",
        "                                sub_dict = {\n",
        "                                    'subreddit': subreddit_name,\n",
        "                                    'id': submission.id,\n",
        "                                    'title': submission.title,\n",
        "                                    'author': str(submission.author),\n",
        "                                    'created_utc': datetime.fromtimestamp(submission.created_utc),\n",
        "                                    'score': submission.score,\n",
        "                                    'upvote_ratio': submission.upvote_ratio,\n",
        "                                    'num_comments': submission.num_comments,\n",
        "                                    'url': submission.url,\n",
        "                                    'is_self': submission.is_self,\n",
        "                                    'selftext': submission.selftext if submission.is_self else None,\n",
        "                                    'sort_method': sort,\n",
        "                                    'time_filter': time_filter if sort != 'new' and sort != 'hot' else None\n",
        "                                }\n",
        "\n",
        "                                sub_samples.add(tuple(sub_dict.items()))\n",
        "                                time.sleep(sleep_amount)\n",
        "\n",
        "                            print(f\"Collected {len(sub_samples)} samples from r/{subreddit_name} ({sort}/{time_filter})\")\n",
        "                            time.sleep(1)\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error with {sort}/{time_filter}: {str(e)}\")\n",
        "                            continue\n",
        "\n",
        "                # Convert back to list of dicts\n",
        "                sub_samples_list = [dict(items) for items in sub_samples]\n",
        "                all_submissions.extend(sub_samples_list[:sample_size])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error collecting from r/{subreddit_name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return pd.DataFrame(all_submissions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get a Reddit API client ID and secret:\n",
        "\n",
        "1. Visit https://www.reddit.com/prefs/apps\n",
        "2. Sign in to your Reddit account\n",
        "3. Click \"create app\" or \"create another app\" button\n",
        "4. Fill out the form:\n",
        "   - Name: your app name\n",
        "   - Select \"web app\" or \"script\" depending on your needs\n",
        "   - Description: brief description of your app\n",
        "   - About URL: optional website URL\n",
        "   - Redirect URI: use http://localhost:8000 for testing\n",
        "5. Click \"create app\"\n",
        "\n",
        "After creation, you'll see:\n",
        "- Client ID: under your app name\n",
        "- Client secret: displayed as \"secret\"\n",
        "\n",
        "Note that Reddit has significantly restricted API access with new usage limitations and pricing since April 2023, which may affect your development plans.match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObRqrgTlVB-e",
        "outputId": "9d43fd2f-9d23-4278-819e-f97de363b9b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # You'll need to get these from your Reddit API application\n",
        "    CLIENT_ID = 'YOUR_CLIENT_ID'\n",
        "    CLIENT_SECRET = \"YOUR_CLIENT_SECRET\"\n",
        "    USER_AGENT = f\"script:data_sampler:v1.0 (by /u/{\"YOUR_USERNAME\"})\"\n",
        "\n",
        "    sampler = RedditSampler(CLIENT_ID, CLIENT_SECRET, USER_AGENT)\n",
        "\n",
        "\n",
        "\n",
        "    # Get samples\n",
        "    samples_df = sampler.get_samples(\n",
        "        subreddits=subreddits,\n",
        "        sample_size=sample_size,\n",
        "        submission_type=\"all\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxKANLxWVB-e",
        "outputId": "e2188895-c416-44cc-dc80-757d99b16205"
      },
      "outputs": [],
      "source": [
        "samples_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OauOIcjVB-e",
        "outputId": "6466024e-f8fa-4f55-b07d-9d2de37b229f"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "# now\n",
        "now = datetime.now()\n",
        "format = '%y-%m-%dT%H-%M-%S'\n",
        "date_string = now.strftime(format)\n",
        "date_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyIX5cfuVB-e",
        "outputId": "8c632b88-d666-4bac-ed9c-c2ea4a3e554e"
      },
      "outputs": [],
      "source": [
        "samples_df['subreddit'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sju6lYWjVB-e",
        "outputId": "d3b37f7b-e72e-4e12-8e6a-ee6df47daa7e"
      },
      "outputs": [],
      "source": [
        "samples_df['title_text'] = samples_df['title']+\"\\n---\\n\"+samples_df['selftext']\n",
        "\n",
        "# Save to CSV\n",
        "samples_df.to_csv(f\"data/input/reddit_10_mental_health_{date_string}_incomplete.csv\", index=False)\n",
        "print(f\"Saved {len(samples_df)} total samples to reddit_samples.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqxBLIOtVB-e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "text_psychometrics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

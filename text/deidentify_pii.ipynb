{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNK29YfmvWzBoHUMR2w0rY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielmlow/tutorials/blob/main/text/deidentify_pii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tutorials: https://microsoft.github.io/presidio/tutorial/\n",
        "\n",
        "You might want to download other languages\n"
      ],
      "metadata": {
        "id": "Nub7mhF3FEOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install presidio-analyzer\n",
        "!pip install presidio-anonymizer\n",
        "!python -m spacy download en_core_web_lg # you can download other languages"
      ],
      "metadata": {
        "id": "erodrS-rE_5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text in txt files\n"
      ],
      "metadata": {
        "id": "RdrXNPnk3_H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "anonymized_text_all = []\n",
        "\n",
        "path = './data/transcripts/'\n",
        "\n",
        "output_dir = './data/deidentified_transcripts/'\n",
        "\n",
        "transcript_paths = []\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    # Skip hidden directories\n",
        "    dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
        "\n",
        "    for file in files:\n",
        "        if file.endswith('_transcript'):\n",
        "            full_path = os.path.join(root, file)\n",
        "            # Convert to forward slashes for consistency\n",
        "            full_path = full_path.replace(os.sep, '/')\n",
        "            transcript_paths.append(full_path)\n",
        "\n",
        "\n",
        "# loop through txt files:\n",
        "\n",
        "for path in transcript_paths:\n",
        "  with open(path + path, 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "    # Set up the engine, loads the NLP module (spaCy model by default)\n",
        "    # and other PII recognizers\n",
        "    analyzer = AnalyzerEngine()\n",
        "\n",
        "    # Call analyzer to get results\n",
        "    results = analyzer.analyze(text=text,\n",
        "                            entities=[\"PERSON\", \"PHONE_NUMBER\",\"NUMBER\"], #You could add LOCATION\n",
        "                            language='en')\n",
        "    # print(results)\n",
        "\n",
        "    # Analyzer results are passed to the AnonymizerEngine for anonymization\n",
        "\n",
        "    anonymizer = AnonymizerEngine()\n",
        "\n",
        "    anonymized_text = anonymizer.anonymize(text=text,analyzer_results=results)\n",
        "\n",
        "\n",
        "\n",
        "    # Save deidentified txt in same folder\n",
        "\n",
        "    # Option A\n",
        "    # paht = path.replace('.txt', '')\n",
        "    # with open(path + '_deidentified.txt', 'w') as f:\n",
        "\n",
        "    # Option B:\n",
        "    filename = path.replace('.txt', '').split('/')[-1]\n",
        "\n",
        "    with open(output_dir + filename + '_deidentified.txt', 'w') as f:\n",
        "        f.write(anonymized_text.text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kGHFah1h1XvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If you have a DF"
      ],
      "metadata": {
        "id": "5SD5XvpD33zE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0eizkiBE8Cb"
      },
      "outputs": [],
      "source": [
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "anonymized_text_all = []\n",
        "\n",
        "\n",
        "for text in tqdm(df['Transcript'].tolist()):\n",
        "\n",
        "\n",
        "    # Set up the engine, loads the NLP module (spaCy model by default)\n",
        "    # and other PII recognizers\n",
        "    analyzer = AnalyzerEngine()\n",
        "\n",
        "    # Call analyzer to get results\n",
        "    results = analyzer.analyze(text=text,\n",
        "                            entities=[\"PERSON\",\"NAME\", \"PHONE_NUMBER\",\"NUMBER\"], #You could add LOCATION\n",
        "                            language='en')\n",
        "    # print(results)\n",
        "\n",
        "    # Analyzer results are passed to the AnonymizerEngine for anonymization\n",
        "\n",
        "    anonymizer = AnonymizerEngine()\n",
        "\n",
        "    anonymized_text = anonymizer.anonymize(text=text,analyzer_results=results)\n",
        "    anonymized_text_all.append(text)\n",
        "\n",
        "df['Transcript_deidentified'] = anonymized_text_all\n"
      ]
    }
  ]
}